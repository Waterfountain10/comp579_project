A.L.E: Arcade Learning Environment (version 0.10.2+c9d4b19)
[Powered by Stella]
A.L.E: Arcade Learning Environment (version 0.10.2+c9d4b19)
[Powered by Stella]
A.L.E: Arcade Learning Environment (version 0.10.2+c9d4b19)
[Powered by Stella]
A.L.E: Arcade Learning Environment (version 0.10.2+c9d4b19)
[Powered by Stella]
A.L.E: Arcade Learning Environment (version 0.10.2+c9d4b19)
[Powered by Stella]
{'useDouble': False, 'usePrioritized': False, 'useDuel': False, 'useNoisy': False, 'useDistributive': True, 'useNstep': False}
cuda
=============================================================
Beginning training trial 1 for Distributive.npy
=============================================================
Episodes:   0%|          | 0/2200 [00:00<?, ?it/s]{'useDouble': True, 'usePrioritized': False, 'useDuel': False, 'useNoisy': False, 'useDistributive': False, 'useNstep': False}
cuda
=============================================================
Beginning training trial 1 for Double.npy
=============================================================
Episodes:   0%|          | 0/2200 [00:00<?, ?it/s]Episodes:   0%|          | 1/2200 [00:00<25:22,  1.44it/s]Episodes:   0%|          | 1/2200 [00:00<25:22,  1.44it/s, reward=100.0, avg=100.0, steps=213, ε=0.998]Episodes:   0%|          | 1/2200 [00:00<33:52,  1.08it/s]Episodes:   0%|          | 1/2200 [00:00<33:52,  1.08it/s, reward=150.0, avg=150.0, steps=208, ε=0.998]Episodes:   0%|          | 2/2200 [00:01<30:22,  1.21it/s, reward=100.0, avg=100.0, steps=213, ε=0.998]Episodes:   0%|          | 2/2200 [00:01<30:22,  1.21it/s, reward=100.0, avg=100.0, steps=259, ε=0.996]Episodes:   0%|          | 2/2200 [00:01<34:01,  1.08it/s, reward=150.0, avg=150.0, steps=208, ε=0.998]Episodes:   0%|          | 2/2200 [00:01<34:01,  1.08it/s, reward=250.0, avg=200.0, steps=213, ε=0.997]Episodes:   0%|          | 3/2200 [00:02<32:37,  1.12it/s, reward=100.0, avg=100.0, steps=259, ε=0.996]Episodes:   0%|          | 3/2200 [00:02<32:37,  1.12it/s, reward=200.0, avg=133.3, steps=285, ε=0.994]Episodes:   0%|          | 3/2200 [00:03<39:20,  1.07s/it, reward=250.0, avg=200.0, steps=213, ε=0.997]Episodes:   0%|          | 3/2200 [00:03<39:20,  1.07s/it, reward=300.0, avg=233.3, steps=287, ε=0.995]Episodes:   0%|          | 4/2200 [00:03<32:47,  1.12it/s, reward=200.0, avg=133.3, steps=285, ε=0.994]Episodes:   0%|          | 4/2200 [00:03<32:47,  1.12it/s, reward=200.0, avg=150.0, steps=269, ε=0.992]Episodes:   0%|          | 5/2200 [00:04<36:06,  1.01it/s, reward=200.0, avg=150.0, steps=269, ε=0.992]Episodes:   0%|          | 5/2200 [00:04<36:06,  1.01it/s, reward=450.0, avg=210.0, steps=326, ε=0.990]Episodes:   0%|          | 4/2200 [00:04<48:09,  1.32s/it, reward=300.0, avg=233.3, steps=287, ε=0.995]Episodes:   0%|          | 4/2200 [00:04<48:09,  1.32s/it, reward=550.0, avg=312.5, steps=391, ε=0.992]Episodes:   0%|          | 6/2200 [00:05<34:04,  1.07it/s, reward=450.0, avg=210.0, steps=326, ε=0.990]Episodes:   0%|          | 6/2200 [00:05<34:04,  1.07it/s, reward=100.0, avg=191.7, steps=238, ε=0.988]Episodes:   0%|          | 5/2200 [00:05<44:22,  1.21s/it, reward=550.0, avg=312.5, steps=391, ε=0.992]Episodes:   0%|          | 5/2200 [00:05<44:22,  1.21s/it, reward=250.0, avg=300.0, steps=243, ε=0.990]Episodes:   0%|          | 7/2200 [00:06<31:34,  1.16it/s, reward=100.0, avg=191.7, steps=238, ε=0.988]Episodes:   0%|          | 7/2200 [00:06<31:34,  1.16it/s, reward=150.0, avg=185.7, steps=206, ε=0.986]{'useDouble': False, 'usePrioritized': False, 'useDuel': False, 'useNoisy': True, 'useDistributive': False, 'useNstep': False}
cuda
=============================================================
Beginning training trial 1 for Noisy.npy
=============================================================
Episodes:   0%|          | 0/2200 [00:00<?, ?it/s]Episodes:   0%|          | 8/2200 [00:07<31:50,  1.15it/s, reward=150.0, avg=185.7, steps=206, ε=0.986]Episodes:   0%|          | 8/2200 [00:07<31:50,  1.15it/s, reward=300.0, avg=200.0, steps=241, ε=0.984]{'useDouble': False, 'usePrioritized': False, 'useDuel': True, 'useNoisy': False, 'useDistributive': False, 'useNstep': False}
cuda
=============================================================
Beginning training trial 1 for Duel.npy
=============================================================
Episodes:   0%|          | 0/2200 [00:00<?, ?it/s]Episodes:   0%|          | 6/2200 [00:07<46:26,  1.27s/it, reward=250.0, avg=300.0, steps=243, ε=0.990]Episodes:   0%|          | 6/2200 [00:07<46:26,  1.27s/it, reward=150.0, avg=275.0, steps=254, ε=0.988]Episodes:   0%|          | 9/2200 [00:08<39:53,  1.09s/it, reward=300.0, avg=200.0, steps=241, ε=0.984]Episodes:   0%|          | 9/2200 [00:08<39:53,  1.09s/it, reward=450.0, avg=227.8, steps=310, ε=0.982]Episodes:   0%|          | 1/2200 [00:01<1:09:58,  1.91s/it]Episodes:   0%|          | 1/2200 [00:01<1:09:58,  1.91s/it, reward=100.0, avg=100.0, steps=228]Episodes:   0%|          | 7/2200 [00:09<55:15,  1.51s/it, reward=150.0, avg=275.0, steps=254, ε=0.988]Episodes:   0%|          | 7/2200 [00:09<55:15,  1.51s/it, reward=200.0, avg=264.3, steps=237, ε=0.986]{'useDouble': False, 'usePrioritized': True, 'useDuel': False, 'useNoisy': False, 'useDistributive': False, 'useNstep': False}
cuda
=============================================================
Beginning training trial 1 for Prioritized.npy
=============================================================
Episodes:   0%|          | 0/2200 [00:00<?, ?it/s]Episodes:   0%|          | 1/2200 [00:02<1:36:32,  2.63s/it]Episodes:   0%|          | 1/2200 [00:02<1:36:32,  2.63s/it, reward=800.0, avg=800.0, steps=490, ε=0.996]Episodes:   0%|          | 10/2200 [00:09<40:12,  1.10s/it, reward=450.0, avg=227.8, steps=310, ε=0.982]Episodes:   0%|          | 10/2200 [00:09<40:12,  1.10s/it, reward=200.0, avg=225.0, steps=211, ε=0.981]Episodes:   0%|          | 1/2200 [00:01<47:57,  1.31s/it]Episodes:   0%|          | 1/2200 [00:01<47:57,  1.31s/it, reward=150.0, avg=150.0, steps=208, ε=0.998]Episodes:   0%|          | 11/2200 [00:11<41:45,  1.14s/it, reward=200.0, avg=225.0, steps=211, ε=0.981]Episodes:   0%|          | 11/2200 [00:11<41:45,  1.14s/it, reward=100.0, avg=225.0, steps=208, ε=0.979]Episodes:   0%|          | 2/2200 [00:03<1:07:34,  1.84s/it, reward=800.0, avg=800.0, steps=490, ε=0.996]Episodes:   0%|          | 2/2200 [00:03<1:07:34,  1.84s/it, reward=150.0, avg=475.0, steps=198, ε=0.995]Episodes:   0%|          | 8/2200 [00:11<1:08:19,  1.87s/it, reward=200.0, avg=264.3, steps=237, ε=0.986]Episodes:   0%|          | 8/2200 [00:11<1:08:19,  1.87s/it, reward=150.0, avg=250.0, steps=277, ε=0.984]Episodes:   0%|          | 2/2200 [00:05<1:38:02,  2.68s/it, reward=100.0, avg=100.0, steps=228]Episodes:   0%|          | 2/2200 [00:05<1:38:02,  2.68s/it, reward=300.0, avg=200.0, steps=294]Episodes:   1%|          | 12/2200 [00:12<43:52,  1.20s/it, reward=100.0, avg=225.0, steps=208, ε=0.979]Episodes:   1%|          | 12/2200 [00:12<43:52,  1.20s/it, reward=100.0, avg=225.0, steps=227, ε=0.977]Episodes:   0%|          | 2/2200 [00:03<59:54,  1.64s/it, reward=150.0, avg=150.0, steps=208, ε=0.998]Episodes:   0%|          | 2/2200 [00:03<59:54,  1.64s/it, reward=250.0, avg=200.0, steps=245, ε=0.997]Episodes:   0%|          | 3/2200 [00:05<1:04:16,  1.76s/it, reward=150.0, avg=475.0, steps=198, ε=0.995]Episodes:   0%|          | 3/2200 [00:05<1:04:16,  1.76s/it, reward=150.0, avg=366.7, steps=254, ε=0.993]Episodes:   1%|          | 13/2200 [00:13<48:45,  1.34s/it, reward=100.0, avg=225.0, steps=227, ε=0.977]Episodes:   1%|          | 13/2200 [00:13<48:45,  1.34s/it, reward=150.0, avg=220.0, steps=263, ε=0.975]Episodes:   0%|          | 9/2200 [00:14<1:14:51,  2.05s/it, reward=150.0, avg=250.0, steps=277, ε=0.984]Episodes:   0%|          | 9/2200 [00:14<1:14:51,  2.05s/it, reward=200.0, avg=244.4, steps=237, ε=0.982]Episodes:   0%|          | 4/2200 [00:07<1:10:13,  1.92s/it, reward=150.0, avg=366.7, steps=254, ε=0.993]Episodes:   0%|          | 4/2200 [00:07<1:10:13,  1.92s/it, reward=400.0, avg=375.0, steps=310, ε=0.990]Episodes:   0%|          | 3/2200 [00:08<1:45:17,  2.88s/it, reward=300.0, avg=200.0, steps=294]Episodes:   0%|          | 3/2200 [00:08<1:45:17,  2.88s/it, reward=300.0, avg=233.3, steps=257]Episodes:   0%|          | 3/2200 [00:05<1:13:45,  2.01s/it, reward=250.0, avg=200.0, steps=245, ε=0.997]Episodes:   0%|          | 3/2200 [00:05<1:13:45,  2.01s/it, reward=200.0, avg=200.0, steps=300, ε=0.994]